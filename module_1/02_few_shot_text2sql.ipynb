{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4901509a-8316-47a3-879b-544a43b37ef3",
   "metadata": {},
   "source": [
    "# Few-shot text-to-SQL & Divide and Prompt\n",
    "\n",
    "Few-shot text-to-SQL is an approach for querying databases by translating natural language questions into SQL queries, using only a few training examples.\n",
    "\n",
    "Providing just a few examples of natural language questions paired with the equivalent SQL queries allows models to learn the mapping from natural language to SQL.\n",
    "\n",
    "This is also referencing the Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models paper which states that in-context learning (ICL) has emerged as a new approach to various natural language processing tasks, utilizing large language models (LLMs) to make predictions based on context that has been supplemented with a few examples or task-specific instructions.\n",
    "\n",
    "Reference : https://arxiv.org/abs/2305.12586"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a6bb4",
   "metadata": {},
   "source": [
    "**Suggested SageMaker JupterLab Notebook Environment set up is as follows:**\n",
    "\n",
    "Sagemaker Image: sagemaker-distribution-cpu\n",
    "\n",
    "Kernel: Python 3\n",
    "\n",
    "Instance Type: ml.m5.large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26350f6e-2ae8-40c0-86f2-626cc595af71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dependencies installations\n",
    "\n",
    "Here we will install all the required dependencies to run this notebook. **You can ignore the following errors** that may arise due to dependency conflicts for libraries we won't be using in this module:\n",
    "```\n",
    "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
    "dash 2.14.1 requires dash-core-components==2.0.0, which is not installed.\n",
    "dash 2.14.1 requires dash-html-components==2.0.0, which is not installed.\n",
    "dash 2.14.1 requires dash-table==5.0.0, which is not installed.\n",
    "jupyter-ai 2.5.0 requires faiss-cpu, which is not installed.\n",
    "amazon-sagemaker-jupyter-scheduler 3.0.4 requires pydantic==1.*, but you have pydantic 2.6.0 which is incompatible.\n",
    "gluonts 0.13.7 requires pydantic~=1.7, but you have pydantic 2.6.0 which is incompatible.\n",
    "jupyter-ai 2.5.0 requires pydantic~=1.0, but you have pydantic 2.6.0 which is incompatible.\n",
    "jupyter-ai-magics 2.5.0 requires pydantic~=1.0, but you have pydantic 2.6.0 which is incompatible.\n",
    "jupyter-scheduler 2.3.0 requires pydantic~=1.10, but you have pydantic 2.6.0 which is incompatible.\n",
    "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.2 which is incompatible.\n",
    "tensorflow 2.12.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.9.0 which is incompatible.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab234e01-cf6c-4c59-b605-77978be3aa39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m ensurepip --upgrade\n",
    "!pip install -U boto3 --quiet\n",
    "!pip install -U botocore --quiet\n",
    "!pip install langchain --quiet\n",
    "!pip install sqlalchemy --quiet\n",
    "!pip install mysql-connector-python --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f0206-1fe9-46a8-a6ff-c1fb3d045578",
   "metadata": {},
   "source": [
    "#### Now lets import the required modules to run the notbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756999dd-ac11-4b3a-8e43-2c4cdc2ad9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from langchain import PromptTemplate\n",
    "import random\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12765f-10a8-4aae-9e62-4ee7f4e526cc",
   "metadata": {},
   "source": [
    "#### Notebook now initiates the bedrock_client and also the RDS database connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5440f638-94f6-4a74-8c88-e68ca88ea27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2726f3e8-9565-4756-8c3a-2cb390d23b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define variables for database connection details\n",
    "# If the database is deployed by your cloudformation,  you can get these values from the output value of your cloudformation stack\n",
    "db_host = \"<rds endpoint>\"\n",
    "db_password = \"<rds password>\" # specified in your parameters file when deploying cloudformation template\n",
    "db_user = \"dbadmin\" # specified in your parameters file when deploying cloudformation template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ab665-9b2e-4141-b7fb-df3329ac61c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Establish the database connection using the variables\n",
    "mydb = mysql.connector.connect(\n",
    "    host=db_host,\n",
    "    user=db_user,\n",
    "    password=db_password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5934167-da56-48c4-905a-51f515d8f680",
   "metadata": {},
   "source": [
    "#### Use this section to check all the databases already in your test database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ede071-2cdc-4f0c-9042-5acb59909459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mycursor = mydb.cursor()\n",
    "\n",
    "mycursor.execute(\"SHOW DATABASES\")\n",
    "\n",
    "for x in mycursor:\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a8a54-2782-4c4f-8524-6fef2cfa880a",
   "metadata": {},
   "source": [
    "#### Now the notebook will drop the test table and also the test database if it exists. It then proceeds with creation of the table.\n",
    "#### Then it will insert test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dafc38-a0e9-412c-aa00-508c8446afdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mycursor.execute(\"DROP TABLE IF EXISTS LLM_DEMO.TEST_EMPLOYEE_LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b928c6-181c-4bcc-84b6-728aaf261052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mycursor.execute(\"DROP DATABASE IF EXISTS LLM_DEMO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e78bdc-c26d-4029-907b-8d9768d9e501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mycursor.execute(\"CREATE DATABASE LLM_DEMO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47642512-4489-47b7-ba2d-1ef4956e02f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mycursor.execute(\"\"\"\n",
    "CREATE TABLE LLM_DEMO.TEST_EMPLOYEE_LLM -- Table name\n",
    "(EMPID INT(10), -- employee id of the employee\n",
    "NAME VARCHAR(20), -- name of the employee\n",
    "SALARY INT(10), -- salary that the employee gets or makes\n",
    "BONUS INT(10),-- bonus that the employee gets or makes\n",
    "CITY VARCHAR(20), -- city where employees work from or belongs to\n",
    "JOINING_DATE TIMESTAMP,-- date of joining for the employee\n",
    "ACTIVE_EMPLOYEE INT(2), -- whether the employee is active(1) or in active(0)\n",
    "DEPARTMENT VARCHAR(20), -- the deparment name where employee works or belongs to\n",
    "TITLE VARCHAR(20) -- the title in office which employees has or holds\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea4d6e-714e-48af-8141-3911f762a336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (1, 'Xyon McFluff', 50000, 10000, 'New York', '2020-01-01 10:00:00', 1, 'Engineering', 'Manager');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE) \n",
    "VALUES (2, 'Twinkle Luna', 60000, 5000, 'Chicago', '2018-05-15 11:30:00', 1, 'Sales', 'Executive');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (3, 'Zorfendorf', 45000, 2000, 'Miami', '2021-09-01 09:15:00', 1, 'Marketing', 'Associate');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)  \n",
    "VALUES (4, 'Gloobinorg', 72000, 8000, 'Seattle', '2017-04-05 14:20:00', 1, 'IT', 'Manager');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (5, 'Bonkliwop', 65000, 6000, 'Denver', '2020-11-24 08:45:00', 1, 'Sales', 'Associate');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (6, 'Ploopdewoop', 55000, 4000, 'Philadelphia', '2019-03-11 10:25:00', 1, 'Marketing', 'Executive');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (7, 'Flooblelobber', 80000, 9000, 'San Francisco', '2016-08-20 12:35:00', 1, 'Engineering', 'Lead');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)  \n",
    "VALUES (8, 'Blippitybloop', 57000, 3000, 'Boston', '2018-12-01 15:00:00', 1, 'Finance', 'Analyst');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (9, 'Snorkeldink', 74000, 7000, 'Atlanta', '2015-10-07 16:15:00', 1, 'IT', 'Lead');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (10, 'Wuggawugga', 69000, 5000, 'Austin', '2017-06-19 13:45:00', 1, 'Engineering', 'Manager'); \"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (11, 'Foofletoot', 62000, 4000, 'San Diego', '2019-02-24 17:30:00', 1, 'Sales', 'Associate');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (12, 'Bonkbonk', 82000, 8000, 'Silicon Valley', '2014-12-05 09:45:00', 1, 'Engineering', 'Director');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (13, 'Zippityzoom', 78000, 7500, 'New York', '2016-03-08 11:00:00', 1, 'IT', 'Manager');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE) \n",
    "VALUES (14, 'Splatchsplatch', 90000, 9500, 'Chicago', '2013-01-26 13:15:00', 1, 'Marketing', 'Director');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)  \n",
    "VALUES (15, 'Wuggles', 85000, 8000, 'Seattle', '2018-07-22 15:30:00', 1, 'Finance', 'Manager');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (16, 'Boingboing', 70000, 6000, 'Miami', '2020-04-11 16:45:00', 1, 'Sales', 'Lead');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (17, 'Zipzoom', 62000, 5000, 'Denver', '2017-09-18 18:00:00', 1, 'Engineering', 'Associate');\"\"\") \n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)  \n",
    "VALUES (18, 'Wooglewoogle', 58000, 3500, 'Philadelphia', '2019-12-24 08:20:00', 1, 'IT', 'Analyst');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE)\n",
    "VALUES (19, 'Flipflopglop', 75000, 7200, 'Boston', '2022-02-14 10:35:00', 1, 'Marketing', 'Lead');\"\"\")\n",
    "\n",
    "mycursor.execute(\"\"\"INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS, CITY, JOINING_DATE, ACTIVE_EMPLOYEE, DEPARTMENT, TITLE) \n",
    "VALUES (20, 'Blipblop', 68000, 6500, 'San Francisco', '2021-08-29 11:50:00', 1, 'Finance', 'Executive');\"\"\")\n",
    "\n",
    "\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49656b39-8010-409b-99a7-6afb01018d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mycursor.execute(\"SELECT * FROM LLM_DEMO.TEST_EMPLOYEE_LLM\")\n",
    "\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "for x in myresult:\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf28a8-0d22-4223-989b-243431149e22",
   "metadata": {},
   "source": [
    "#### The purpose of callDatabase function is to execute SQL queries, typically for retrieving data from a database, and format the results as a string for further processing or display. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401ba7a-de43-410d-8015-a38a60f2b6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to interact with a database using an SQL query.\n",
    "# Arguments:\n",
    "#   llm_generated_response: A string containing an SQL query to execute.\n",
    "# Returns:\n",
    "#   A formatted string containing the results of the executed SQL query.\n",
    "\n",
    "def callDatabase(llm_generated_response):\n",
    "    mycursor = mydb.cursor()\n",
    "\n",
    "    mycursor.execute(llm_generated_response)\n",
    "\n",
    "    myresult = mycursor.fetchall()\n",
    "\n",
    "    output_string = ''\n",
    "    for x in myresult:\n",
    "      output_string = output_string + str(x) + \"\\n\"\n",
    "      print(x)\n",
    "        \n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddaedc7-f395-4d92-9809-8f7b71baa42f",
   "metadata": {},
   "source": [
    "#### The interactWithLLM function uses the Bedrock client to invoke the LLMs. The response from the LLMs is extracted and returned as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc112cf-6681-4566-91b1-c72385ea301f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Interact with a large language model (LLM) to generate text \n",
    "# based on a prompt.\n",
    "#\n",
    "# Arguments:\n",
    "#   prompt: The text prompt to provide to the LLM.\n",
    "#   llm_type: The name of the LLM to use, either 'titan' or 'claude'. \n",
    "#\n",
    "# Returns:\n",
    "#   The text generated by the LLM in response to the prompt.\n",
    "#   \n",
    "# This function:\n",
    "# 1. Prints the llm_type for debugging.\n",
    "# 2. Formats the prompt into the JSON payload expected by each LLM API.\n",
    "# 3. Specifies the parameters for text generation like max tokens, temp.\n",
    "# 4. Calls the Bedrock client to invoke the LLM model API. \n",
    "# 5. Parses the response to extract the generated text.\n",
    "# 6. Returns the generated text string.\n",
    "\n",
    "def interactWithLLM(prompt, type):\n",
    "\n",
    "    if type == \"titan\":\n",
    "        print(\"**THE LLM TYPE IS -->\" + type)\n",
    "        print(\"prompt---->\" + prompt)\n",
    "        # Test for invoke model begins\n",
    "        parameters = {\n",
    "            \"maxTokenCount\": 512,\n",
    "            \"stopSequences\": [],\n",
    "            \"temperature\": 0,\n",
    "            \"topP\": 0.9,\n",
    "        }\n",
    "        body = json.dumps({\"inputText\": prompt, \"textGenerationConfig\": parameters})\n",
    "        modelId = \"amazon.titan-tg1-large\"  # \"amazon.titan-tg1-large\"\n",
    "        accept = \"application/json\"\n",
    "        contentType = \"application/json\"\n",
    "        response = bedrock_client.invoke_model(\n",
    "            body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "        )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "        response_text_titan = response_body.get(\"results\")[0].get(\"outputText\")\n",
    "\n",
    "        return response_text_titan\n",
    "\n",
    "    elif type == \"claude\":\n",
    "        print(\"**THE LLM TYPE IS -->\" + type)\n",
    "        body = json.dumps(\n",
    "            {\n",
    "                \"prompt\": prompt,\n",
    "                \"max_tokens_to_sample\": 2048,\n",
    "                \"temperature\": 1,\n",
    "                \"top_k\": 250,\n",
    "                \"top_p\": 0.999,\n",
    "                \"stop_sequences\": [],\n",
    "            }\n",
    "        )\n",
    "        modelId = \"anthropic.claude-v2\"  # change this to use a different version from the model provider\n",
    "        accept = \"application/json\"\n",
    "        contentType = \"application/json\"\n",
    "        print(\"prompt---->\" + prompt)\n",
    "        response = bedrock_client.invoke_model(\n",
    "            body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "        )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "        response_text_claude = response_body.get(\"completion\")\n",
    "\n",
    "        return response_text_claude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f997f36-a08b-4189-ba98-a410d9063e41",
   "metadata": {},
   "source": [
    "#### Function prepareFinalGenText combines a prompt and database query results to generate text using LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2df84-25e0-4339-958d-3fc4c400d375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to prepare the final generated text by combining a given prompt and database query results.\n",
    "# Arguments:\n",
    "#   prompt_final: A string representing a prompt template for text generation.\n",
    "#   output_string: A string containing formatted database query results.\n",
    "# Returns:\n",
    "#   The final generated text based on the combined prompt and database query results.\n",
    "\n",
    "def prepareFinalGenText(prompt_final,output_string):\n",
    "    prompt_template_for_query_response = PromptTemplate.from_template(prompt_final)\n",
    "\n",
    "    prompt_data_for_query_response = prompt_template_for_query_response.format(question=question_asked,answer=output_string)\n",
    "    #print(prompt_data_for_query_response)\n",
    "    final_response_text = interactWithLLM(prompt_data_for_query_response,'claude')\n",
    "    return final_response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5e5b2-13b1-4f70-9484-56b2ef618cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prompt for the final generated text based on the combined prompt and database query result\n",
    "\n",
    "prompt_final = \"\"\"\n",
    "Human: Based on  the question below\n",
    "\n",
    "{question}\n",
    "\n",
    "the answer was given below. \n",
    "\n",
    "{answer}\n",
    "\n",
    "Provide answer in simple english statement and don't include table or schema names.\n",
    "Assistant: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede97a9-d1af-4eeb-a5f9-f95225a10b34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prompt for in-context SQL generation based on NLP question\n",
    "\n",
    "prompt = \"\"\"\n",
    "Human:  You are a mysql query expert whose output is a valid sql query. \n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "It has the following schema:\n",
    "<table_schema>\n",
    "CREATE TABLE LLM_DEMO.TEST_EMPLOYEE_LLM -- Table name\n",
    "(EMPID INT(10), -- employee id of the employee\n",
    "NAME VARCHAR(20), -- name of the employee\n",
    "SALARY INT(10), -- salary that the employee gets or makes\n",
    "BONUS INT(10),-- bonus that the employee gets or makes\n",
    "CITY VARCHAR(20), -- city where employees work from or belongs to\n",
    "JOINING_DATE TIMESTAMP,-- date of joining for the employee\n",
    "ACTIVE_EMPLOYEE INT(2), -- whether the employee is active(1) or in active(0)\n",
    "DEPARTMENT VARCHAR(20), -- the deparment name where employee works or belongs to\n",
    "TITLE VARCHAR(20) -- the title in office which employees has or holds\n",
    ")\n",
    "<table_schema>\n",
    "\n",
    "The schema name is LLM_DEMO\n",
    "\n",
    "And here is a sample insert statement or record for your reference : \n",
    "\n",
    "INSERT INTO LLM_DEMO.TEST_EMPLOYEE_LLM (EMPID, NAME, SALARY, BONUS,CITY,JOINING_DATE,ACTIVE_EMPLOYEE,DEPARTMENT,TITLE) VALUES (1, 'Stuart', 25000, 5000, 'Seattle','2023-01-21 00:00:01',1,'Applications','Sr. Developer');\n",
    "\n",
    "Please construct a valid SQL statement to answer the following the question, return only the mysql query in between <sql></sql>.:\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Assistant: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de41022-e8fa-423e-a35b-92537e8dfd21",
   "metadata": {},
   "source": [
    "#### The following cells will demonstrate different questions asked in natural language and the SQL generated by the LLM. The output is contained between the < sql > tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f560399-dcd8-49dc-952c-cbeaaf6490be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_asked = \"What is the total count of employees who are active in each department?\"\n",
    "prompt_template_for_query_generate = PromptTemplate.from_template(prompt)\n",
    "prompt_data_for_query_generate = prompt_template_for_query_generate.format(question=question_asked)\n",
    "\n",
    "\n",
    "llm_generated_response = interactWithLLM(prompt_data_for_query_generate,'claude')\n",
    "print(llm_generated_response)\n",
    "\n",
    "llm_generated_response = llm_generated_response.replace(\"<sql>\", \"\") \n",
    "llm_generated_response = llm_generated_response.replace(\"</sql>\", \" \") \n",
    "\n",
    "\n",
    "output_string = callDatabase(llm_generated_response)\n",
    "\n",
    "prepareFinalGenText(prompt_final,output_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617123b-78ea-4631-9871-30c01c7a888a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_asked = \"What is the average salary of employees in each department?\"\n",
    "prompt_template_for_query_generate = PromptTemplate.from_template(prompt)\n",
    "prompt_data_for_query_generate = prompt_template_for_query_generate.format(question=question_asked)\n",
    "\n",
    "llm_generated_response = interactWithLLM(prompt_data_for_query_generate,'claude')\n",
    "print(llm_generated_response)\n",
    "\n",
    "llm_generated_response = llm_generated_response.replace(\"<sql>\", \"\") \n",
    "llm_generated_response = llm_generated_response.replace(\"</sql>\", \" \") \n",
    "\n",
    "output_string = callDatabase(llm_generated_response)\n",
    "\n",
    "prepareFinalGenText(prompt_final,output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0089d0-5adc-426d-be1e-249299c38402",
   "metadata": {},
   "source": [
    "# Divide and Prompt: Chain of Thought Prompting for Text-to-SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963af96a-eea8-4384-a99a-85bc06883654",
   "metadata": {},
   "source": [
    "In Divide-and-Prompt, which first divides the task into subtasks, and then approach each subtask through CoT. Experiments show that these prompts guide LLMs to generate Text-to-SQL with higher execution accuracy.\n",
    "\n",
    "Reference : https://arxiv.org/abs/2304.11556\n",
    "\n",
    "![Divide-and-Prompt example](../images/DnP.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad277b-b171-4d8b-84b3-f6aae2db3057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prompt demonstrating Divide and Prompt: Chain of Thought Prompting for Text-to-SQL\n",
    "\n",
    "prompt_check_modify_sql=\"\"\"\n",
    "Human:  You are a mysql query expert whose output is a valid sql query. \n",
    "\n",
    "It has the following schema:\n",
    "<table_schema>\n",
    "CREATE TABLE LLM_DEMO.TEST_EMPLOYEE_LLM -- Table name\n",
    "(EMPID INT(10), -- column employee id of the employee\n",
    "NAME VARCHAR(20), -- name column of the employee\n",
    "SALARY INT(10), -- salary column that the employee gets or makes\n",
    "BONUS INT(10),-- bonus column that the employee gets or makes\n",
    "CITY VARCHAR(20), -- city column where employees work from or belongs to\n",
    "JOINING_DATE TIMESTAMP,-- date column of joining for the employee\n",
    "ACTIVE_EMPLOYEE INT(2), -- whether the employee is active(1) or in active(0) column \n",
    "DEPARTMENT VARCHAR(20), -- the deparment column name where employee works or belongs to\n",
    "TITLE VARCHAR(20) -- the title column in office which employees has or holds\n",
    ")\n",
    "<table_schema>\n",
    "\n",
    "This is the table(columns):\n",
    "LLM_DEMO.TEST_EMPLOYEE_LLM(EMPID,NAME,SALARY,BONUS,CITY,JOINING_DATE,ACTIVE_EMPLOYEE,DEPARTMENT,TITLE)\n",
    "\n",
    "This is the text : {question_asked}\n",
    "\n",
    "This is the reference SQL : {llm_generated_response}\n",
    "The reference SQL may be correct or incorrect\n",
    "If the reference SQL is correct, just say 'it is correct'\n",
    "If the reference SQL is incorrect, modify the reference SQL and output the correct sql\n",
    "\n",
    "\n",
    "Assistant: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6982ff0b-0f7c-4e13-863c-16655781aede",
   "metadata": {},
   "source": [
    "#### The following cells will demonstrate Divide and Prompt: Chain of Thought Prompting for Text-to-SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cd2a7-5839-4026-af7d-acfc5c4f1a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_asked = \"Which city has the most employees with a title of Lead?\"\n",
    "\n",
    "prompt_template_for_query_generate = PromptTemplate.from_template(prompt)\n",
    "prompt_data_for_query_generate = prompt_template_for_query_generate.format(question=question_asked)\n",
    "\n",
    "llm_generated_response = interactWithLLM(prompt_data_for_query_generate,'claude')\n",
    "print(llm_generated_response)\n",
    "\n",
    "llm_generated_response = llm_generated_response.replace(\"<sql>\", \"\") \n",
    "llm_generated_response = llm_generated_response.replace(\"</sql>\", \" \") \n",
    "\n",
    "prompt_template_for_query_generate = PromptTemplate.from_template(prompt_check_modify_sql)\n",
    "prompt_data_for_query_generate = prompt_template_for_query_generate.format(question_asked=question_asked,llm_generated_response = llm_generated_response)\n",
    "\n",
    "\n",
    "llm_generated_response = interactWithLLM(prompt_data_for_query_generate,'claude')\n",
    "\n",
    "print(llm_generated_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f7b158-f5ab-4626-86ca-bb43fff384be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_asked = \"What is the range of joining dates for employees in each department?\"\n",
    "\n",
    "prompt_template_for_query_generate = PromptTemplate.from_template(prompt)\n",
    "prompt_data_for_query_generate = prompt_template_for_query_generate.format(question=question_asked)\n",
    "\n",
    "llm_generated_response = interactWithLLM(prompt_data_for_query_generate,'claude')\n",
    "print(llm_generated_response)\n",
    "\n",
    "llm_generated_response = llm_generated_response.replace(\"<sql>\", \"\") \n",
    "llm_generated_response = llm_generated_response.replace(\"</sql>\", \" \") \n",
    "\n",
    "prompt_template_for_query_generate = PromptTemplate.from_template(prompt_check_modify_sql)\n",
    "prompt_data_for_query_generate = prompt_template_for_query_generate.format(question_asked=question_asked,llm_generated_response = llm_generated_response)\n",
    "\n",
    "\n",
    "llm_generated_response = interactWithLLM(prompt_data_for_query_generate,'claude')\n",
    "\n",
    "print(llm_generated_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe4767-1ddf-41bd-a17c-97b10e1b7f02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#deliberate wrong table name and column name\n",
    "question_asked = \"What is the range of joining dates for employees in each department?\"\n",
    "llm_generated_response = \"\"\"\n",
    "SELECT DEPARTMENT, AGE, MIN(JOINING_DATE) AS Earliest_Join_Date, MAX(JOINING_DATE) AS Latest_Join_Date\n",
    "FROM LLM_DEMO.TEST_EMPLOYEE_LLM_TEST\n",
    "GROUP BY DEPARTMENT\n",
    "\"\"\"\n",
    "prompt_template_for_query_generate = PromptTemplate.from_template(prompt_check_modify_sql)\n",
    "prompt_data_for_query_generate = prompt_template_for_query_generate.format(question_asked=question_asked,llm_generated_response = llm_generated_response)\n",
    "\n",
    "\n",
    "llm_generated_response = interactWithLLM(prompt_data_for_query_generate,'claude')\n",
    "\n",
    "print(llm_generated_response)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "nl2sql-workshop-WgNAqQfH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
