{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preventing SQL Injection\n",
    "\n",
    "Utilize Prompt Engineering to prevent unsafe SQL statements from generation or execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested SageMaker Environment\n",
    "Sagemaker Image: sagemaker-distribution-cpu\n",
    "\n",
    "Kernel: Python 3\n",
    "\n",
    "Instance Type: ml.m5.large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contents\n",
    "\n",
    "1. [Install Dependencies](#step-1-install-dependencies)\n",
    "1. [Configure Athena and Bedrock Client](#step-2-configure-athena-and-bedrock-client)\n",
    "1. [Prevent SQL Injection with DELETE request](#step-3-Prevent-SQL-Injection-with-DELETE-request)\n",
    "1. [Prevent SQL Injection with UPDATE request](#step-4-Prevent-SQL-Injection-with-UPDATE-request)\n",
    "1. [Apply Read Restrictions](#step-5-Apply-Read-Restrictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objective\n",
    "This notebook will provide code snippets to apply Prompt Engineering to prevent unsafe SQL statements like INSERT, UPDATE, and DELETE from generation and execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Approach to the Text-to-SQL Security\n",
    "\n",
    "SQL Injection is an attack that targets the database layer of an application by injecting rogue SQL statements through user inputs or application parameters. These attacks can lead to unauthorized exposure, modification, or deletion of sensitive data stored in the database.\n",
    "\n",
    "GenAI Security places a strong emphasis on identifying and preventing unsafe SQL statements, particularly those that involve potentially harmful actions such as 'insert', 'update' or 'delete.' The focus here is to create a robust framework by Prompt Engineering that actively identifies and restricts the execution of SQL statements that could compromise data integrity or privacy.\n",
    "\n",
    "For a deeper dive into the challenges and approaches to prevent from Prompt Injection to SQL Injection attacks in text-to-SQL use cases, please read this paper: \n",
    "\n",
    "https://arxiv.org/pdf/2308.01990.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Install Dependencies\n",
    "\n",
    "Here we will install all the required dependencies to run this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m ensurepip --upgrade\n",
    "!pip install \"sqlalchemy\" --quiet\n",
    "!pip install \"boto3~=1.34\"  --quiet\n",
    "!pip install \"jinja2\" --quiet\n",
    "!pip install \"botocore\" --quiet\n",
    "!pip install \"pandas\" --quiet\n",
    "!pip install \"PyAthena\" --quiet\n",
    "!pip install langchain --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import sys\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "sys.path.append('../')\n",
    "from libs.din_sql import din_sql_lib as dsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Configure Athena and Bedrock Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace those variables with your set up ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ATHENA_RESULTS_S3_LOCATION = \"<workshop bucket name>\" # available in cloudformation outputs\n",
    "ATHENA_CATALOG_NAME = \"<athena catalog name>\" # available in cloudformation outputs\n",
    "DB_NAME = \"tpcds1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retry_config = Config(retries = {'max_attempts': 100})\n",
    "bedrock_region = athena_region = boto3.session.Session().region_name\n",
    "session = boto3.Session(region_name=bedrock_region)\n",
    "bedrock = session.client('bedrock-runtime', region_name=bedrock_region, config=retry_config)\n",
    "accept = 'application/json'\n",
    "content_type = 'application/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id='anthropic.claude-v2'\n",
    "\n",
    "from libs.din_sql import din_sql_lib as dsl\n",
    "din_sql = dsl.DIN_SQL(bedrock_model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "din_sql.athena_connect(catalog_name=ATHENA_CATALOG_NAME, \n",
    "               db_name=DB_NAME, \n",
    "               s3_prefix=ATHENA_RESULTS_S3_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = {'customer': 'c_customer_sk|c_customer_id|c_current_cdemo_sk|c_current_hdemo_sk|c_current_addr_sk|c_first_shipto_date_sk|c_first_sales_date_sk|c_salutation|c_first_name|c_last_name|c_preferred_cust_flag|c_birth_day|c_birth_month|c_birth_year|c_birth_country|c_login|c_email_address|c_last_review_date_sk|'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Prevent SQL injection with delete request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A user request to delete tables, which is potentially cause damage to the database\n",
    "query = \"delete all the customers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt without protection of SQL operations\n",
    "In the initial version of prompt below, youâ€™ll see that there are baseline protections in the instruction such as to use only the columns from the schema and never query for all the columns but relevant columns given the query. However, there is no protection of the unsafe operations such as \"insert\", \"delete\" or \"udpate\", which will alter the database data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prompt without protection of SQL injection\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\\n\\nHuman:\n",
    "        Read database schema {schema} which contains a json list of table names and their pipe-delimited schemas.\n",
    "        Use the schema, first create a syntactically correct awsathena query to answer the question {input_question}\n",
    "        Instructions:\n",
    "           Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
    "           Pay attention to use only the column names that you can see in the schema description. \n",
    "           Be careful to not query for columns that do not exist. \n",
    "           Pay attention to which column is in which table. \n",
    "           Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n",
    "           Return the sql query inside the <SQL></SQL> tab.\n",
    "          \n",
    "        <Question>\"How many users do we have?\"</Question>\n",
    "        <SQL>SELECT SUM(users) FROM customers</SQL>\n",
    "\n",
    "        <Question>\"How many users do we have for Mobile?\"</Question>\n",
    "        <SQL>SELECT SUM(users) FROM customer WHERE source_medium='Mobile'</SQL>\n",
    "          \n",
    "        <Question>{input_question}</Question>\n",
    "        \\n\\n Assistant: \"\"\"\n",
    ")\n",
    "prompt_data= prompt_template.format(schema=schema,input_question = query)\n",
    "#print(prompt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Formulate Bedrock Model Invoke Body\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 1500,\"temperature\":0.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without protection, the LLM generates the delete sql, which will delete all the customer records if executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Invoke model to generate response\n",
    "response = bedrock.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "sql = response_body['completion']\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prompt below shows how to avoid generating unsafe sql like \"delete\"\n",
    "#### Adding this instruction and example to the prompt:\n",
    "\n",
    "\n",
    "\"Reject any question that ask for insert, update, and delete actions\"\n",
    "\n",
    "  \"\\<Question\\>\"Delete all the customers\"\\</Question\\>\"\n",
    "  \n",
    "  \"\\<SQL\\>I don't have permission to generate or execute SQLs which can change data\\</SQL\\>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prompt with protection of SQL injection\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\\n\\nHuman:\n",
    "        Read database schema {schema} which contains a json list of table names and their pipe-delimited schemas.\n",
    "        Use the schema, first create a syntactically correct awsathena query to answer the question {input_question}\n",
    "        Instructions:\n",
    "           Reject any question that ask for insert, update, and delete actions  \n",
    "           Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
    "           Pay attention to use only the column names that you can see in the schema description. \n",
    "           Be careful to not query for columns that do not exist. \n",
    "           Pay attention to which column is in which table. \n",
    "           Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n",
    "           Return the sql query inside the <SQL></SQL> tab.\n",
    "          \n",
    "        <Question>\"How many users do we have?\"</Question>\n",
    "        <SQL>SELECT SUM(users) FROM customers</SQL>\n",
    "\n",
    "        <Question>\"How many users do we have for Mobile?\"</Question>\n",
    "        <SQL>SELECT SUM(users) FROM customer WHERE source_medium='Mobile'</SQL>\n",
    "\n",
    "        <Question>\"Delete all the customers\"</Question>\n",
    "        <SQL>I don't have permission to generate or execute SQLs which can change data</SQL>\n",
    "          \n",
    "        <Question>{input_question}</Question>\n",
    "        \\n\\n Assistant: \"\"\"\n",
    ")\n",
    "prompt_data= prompt_template.format(schema=schema,input_question = query)\n",
    "#print(prompt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Formulate Bedrock Model Invoke Body\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 1500,\"temperature\":0.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Given the same user request, with improved prompt, the LLM generates different answer to avoid deleting all the customers from the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Invoke model to generate response\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "sql = response_body['completion']\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Prevent SQL injection with update request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A user query to massively update the table in a database\n",
    "query = \"update all the customers who were born after 2000 and set their first name to 'John'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt without protection of SQL operations\n",
    "In the initial version of prompt below, youâ€™ll see that there are baseline protections in the instruction such as to use only the columns from the schema and never query for all the columns but relevant columns given the query. However, there is no protection of the unsafe operations such as \"insert\", \"delete\" or \"udpate\", which will alter the database data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prompt without protection of SQL injection\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\\n\\nHuman:\n",
    "        Read database schema {schema} which contains a json list of table names and their pipe-delimited schemas.\n",
    "        Use the schema, first create a syntactically correct awsathena query to answer the question {input_question}\n",
    "        Instructions:\n",
    "           Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
    "           Pay attention to use only the column names that you can see in the schema description. \n",
    "           Be careful to not query for columns that do not exist. \n",
    "           Pay attention to which column is in which table. \n",
    "           Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n",
    "           Return the sql query inside the <SQL></SQL> tab.\n",
    "          \n",
    "        <Question>\"How many users do we have?\"</Question>\n",
    "        <SQL>SELECT SUM(users) FROM customers</SQL>\n",
    "\n",
    "        <Question>\"How many users do we have for Mobile?\"</Question>\n",
    "        <SQL>SELECT SUM(users) FROM customer WHERE source_medium='Mobile'</SQL>\n",
    "          \n",
    "        <Question>{input_question}</Question>\n",
    "        \\n\\n Assistant: \"\"\"\n",
    ")\n",
    "prompt_data= prompt_template.format(schema=schema,input_question = query)\n",
    "#print(prompt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Formulate Bedrock Model Invoke Body\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 1500,\"temperature\":0.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without operation protection, the LLM generates the update sql, which will update all the customers born before 2000 if executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Invoke model to generate response\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "sql = response_body['completion']\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prompt below shows how to avoid generating unsafe udpate sql in this example.\n",
    "#### Adding this instruction and example to the prompt:\n",
    "\n",
    "\n",
    "\"Reject any question that ask for insert, update, and delete actions. Don't generate SQL statement.\"\n",
    "\n",
    "  \"\\<Question\\>Delete all the customers\\</Question\\>\"\n",
    "  \n",
    "  \"\\<SQL\\>I don't have permission to generate or execute SQLs which can change data\\</SQL\\>\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prompt with protection of SQL injection\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\\n\\nHuman:\n",
    "        Read database schema {schema} which contains a json list of table names and their pipe-delimited schemas.\n",
    "        Use the schema, first create a syntactically correct awsathena query to answer the question {input_question}\n",
    "        Instructions:\n",
    "           Reject any question that ask for insert, update, and delete actions. Don't generate SQL statement.  \n",
    "           Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
    "           Pay attention to use only the column names that you can see in the schema description. \n",
    "           Be careful to not query for columns that do not exist. \n",
    "           Pay attention to which column is in which table. \n",
    "           Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n",
    "           Return the sql query inside the <SQL></SQL> tab.\n",
    "          \n",
    "        <Question>\"How many customers do we have?\"</Question>\n",
    "        <SQL>SELECT SUM(customers) FROM customers</SQL>\n",
    "\n",
    "        <Question>\"How many customers do we have for Mobile?\"</Question>\n",
    "        <SQL>SELECT SUM(customers) FROM customer WHERE source_medium='Mobile'</SQL>\n",
    "\n",
    "        <Question>\"Delete all the customers\"</Question>\n",
    "        <SQL>I don't have permission to generate or execute SQLs which can change data</SQL>\n",
    "          \n",
    "        <Question>{input_question}</Question>\n",
    "        \\n\\n Assistant: \"\"\"\n",
    ")\n",
    "prompt_data= prompt_template.format(schema=schema,input_question = query)\n",
    "#print(prompt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Formulate Bedrock Model Invoke Body\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 1500,\"temperature\":0.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given the same user request, with the improved prompt, the LLM does not generate the SQL statement and provides a warning message for SQL statement that can modify database data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Invoke model to generate response\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "sql = response_body['completion']\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Apply Read Restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### This user query is potentially to retrieve information that the user does not have permission for and comprimise data privacy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A query to retrieve all the customer information that the customer should not have access to.\n",
    "query = \"give me customer information for customers who were born before 1930\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prompt without read restrictions\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\\n\\nHuman:\n",
    "        Read database schema {schema} which contains a json list of table names and their pipe-delimited schemas.\n",
    "        Use the schema, first create a syntactically correct awsathena query to answer the question {input_question} \n",
    "        Instructions:\n",
    "           Reject any question that ask for insert, update, and delete actions  \n",
    "           Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
    "           Pay attention to use only the column names that you can see in the schema description. \n",
    "           Be careful to not query for columns that do not exist. \n",
    "           Pay attention to which column is in which table. \n",
    "           Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n",
    "           Return the sql query inside the <SQL></SQL> tab.\n",
    "        \n",
    "        <Question>\"How many customers do we have?\"</Question>\n",
    "        <SQL>SELECT SUM(customers) FROM customers</SQL>\n",
    "\n",
    "        <Question>\"How many customers do we have for Mobile?\"</Question>\n",
    "        <SQL>SELECT SUM(customers) FROM customer WHERE source_medium='Mobile'</SQL>\n",
    "\n",
    "        <Question>\"Delete all the customers\"</Question>\n",
    "        <SQL>I don't have permission to generate or execute SQLs which can change data</SQL>\n",
    "          \n",
    "        <Question>{input_question}</Question>\n",
    "        \\n\\n Assistant: \"\"\"\n",
    ")\n",
    "prompt_data= prompt_template.format(schema=schema,input_question = query)\n",
    "#print(prompt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Formulate Bedrock Model Invoke Body\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 1500,\"temperature\":0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Invoke model to generate response\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "sql = response_body['completion']\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without read restriction in prompt, the LLM generates sql statement to retrieve all the customer information, which the user should not have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = din_sql.query(sql.split('<SQL>')[1].split('</SQL>')[0])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prompt below shows how to apply read restrictions\n",
    "#### Adding this instruction and example to the prompt and provide customer_id at runtime.\n",
    "\n",
    "\n",
    "\"The question will be asked by a customer with a customer_id. The query should only return results for the customer_id of the customer asking the question as to protect the privacy of other customers. \n",
    "For example, a customer with customer_id='A' can not see the information of customer with customer_id='B'. The customer_id of the customer asking the question is: {customer_id}\"\n",
    "\n",
    "\"\\<Question\\>Give me customer information for Mobile\\</Question\\>\"\n",
    "\n",
    "\"\\<SQL\\>SELECT * FROM customer WHERE source_medium='Mobile' and customer_id = {customer_id} \\</SQL\\>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prompt with protection of SQL injection\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\\n\\nHuman:\n",
    "        Read database schema {schema} which contains a json list of table names and their pipe-delimited schemas.\n",
    "        Use the schema, first create a syntactically correct awsathena query to answer the question {input_question} \n",
    "        Instructions:\n",
    "           The question will be asked by a customer with a customer_id. The query should only return results for the customer_id of the customer asking the question as to protect the privacy of other customers. \n",
    "           For example, a customer with customer_id='A' can not see the information of customer with customer_id='B'. The customer_id of the customer asking the question is: {customer_id}\n",
    "           Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
    "           Pay attention to use only the column names that you can see in the schema description. \n",
    "           Be careful to not query for columns that do not exist. \n",
    "           Pay attention to which column is in which table. \n",
    "           Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n",
    "           Return the sql query inside the <SQL></SQL> tab.\n",
    "        \n",
    "        <Question>\"How many customers do we have?\"</Question>\n",
    "        <SQL>SELECT SUM(customers) FROM customers</SQL>\n",
    "\n",
    "        <Question>\"How many customers do we have for Mobile?\"</Question>\n",
    "        <SQL>SELECT SUM(customers) FROM customer WHERE source_medium='Mobile'</SQL>\n",
    "        \n",
    "        <Question>\"Give me customer information for Mobile\"</Question>\n",
    "        <SQL>SELECT * FROM customer WHERE source_medium='Mobile' and customer_id = {customer_id} </SQL>\n",
    "          \n",
    "        <Question>{input_question}</Question>\n",
    "        \\n\\n Assistant: \"\"\"\n",
    ")\n",
    "prompt_data= prompt_template.format(schema=schema,input_question = query, customer_id = 'AAAAAAAABMLCAAAA')\n",
    "#print(prompt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Formulate Bedrock Model Invoke Body\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 1500,\"temperature\":0.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Given the same user request, with the improved prompt, the LLM generates different answer to apply read restrictions\n",
    "In this case, it only returned the customer information for the specified customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Invoke model to generate response\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=model_id, accept=accept, contentType=content_type)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "sql = response_body['completion']\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = din_sql.query(sql.split('<SQL>')[1].split('</SQL>')[0])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
