{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0621f124-5629-46b5-a4b9-32d008c43493",
   "metadata": {},
   "source": [
    "## Text-to-SQL on a biomedical dataset, optimized for low latency on a single-table\n",
    "---\n",
    "We show here how to build a conversational chatbot that is able to extract information from a relational database with a single table. This is a relatively simple example of text-to-SQL, as there are no joins required. We focus here on showing how to optimize latency using the [SQLDatabaseToolkit](https://python.langchain.com/v0.2/docs/integrations/toolkits/sql_database/) from [LangChain](https://www.langchain.com).\n",
    "\n",
    "In the generic case, SQLDatabaseToolkit uses the ReAct framework to make multiple calls to the LLM: to ask the database what tables it contains, to ask the database for the schema of a subset of those tables, to test a possible SQL query, to run a query, and more. Given that we know the database has only one table we can make fewer calls to the LLM and hence reduce the latency of the overall text-to-SQL process.\n",
    "\n",
    "We use the following database of diabetes patients, which has been downloaded for you as the file `diabetes.csv`:\n",
    "```\n",
    "@article{Machado2024,\n",
    "    author = \"Angela Machado\",\n",
    "    title = \"{diabetes.csv}\",\n",
    "    year = \"2024\",\n",
    "    month = \"3\",\n",
    "    url = \"https://figshare.com/articles/dataset/diabetes_csv/25421347\",\n",
    "    doi = \"10.6084/m9.figshare.25421347.v1\"\n",
    "}\n",
    "```\n",
    "\n",
    "Note that the following `pip install` commands may generate warnings: you can safely ignore these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe41174b-9c71-47ac-b53e-aa0161241dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -qU openpyxl langchain boto3\n",
    "%pip install -qU langchain-community langchain-aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a3512-34dd-4488-8e94-efb0ef48b7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List, Tuple\n",
    "import itertools\n",
    "from time import time\n",
    "\n",
    "import jinja2\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "import sqlite3\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_community.agent_toolkits.sql.base import create_sql_agent\n",
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "sys.path.append('../')\n",
    "import utilities as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87d970-10f2-4e18-a487-21e59dc44a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "# model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "con = sqlite3.connect(\"test.db\")\n",
    "jenv = jinja2.Environment(trim_blocks=True, lstrip_blocks=True)\n",
    "# This is a useful way to keep track of tool invocations:\n",
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "#os.environ[\"LANGCHAIN_API_KEY\"] = \"...\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"\n",
    "\n",
    "is_conversational = True\n",
    "force_setup_db = False\n",
    "do_few_shot_prompting = False\n",
    "show_SQL = True\n",
    "\n",
    "llm = ChatBedrock(model_id=model_id, region_name=\"us-west-2\")\n",
    "db = SQLDatabase.from_uri(\"sqlite:///test.db\")\n",
    "context = db.get_context()\n",
    "chain = create_sql_query_chain(llm, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f56ad-56de-4a56-bd70-36b6ca1ae7cf",
   "metadata": {},
   "source": [
    "### Load the test data into a database\n",
    "\n",
    "First, we load the CSV file into a DataFrame and take a look at some rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337b4ba-3ab5-4968-a5a8-7e1050a57c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278403a-6731-48c0-ad70-e84d4f6f1b45",
   "metadata": {},
   "source": [
    "Next, we load this data into a SQLite database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3d369b-fda3-4399-b07b-284bc2cde2e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_db():\n",
    "    print(\"Setting up DB\")\n",
    "    df.to_sql(name=\"patients\", con=con, if_exists=\"replace\", index=True)\n",
    "    con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e801b91-36b5-439d-bc73-3a4a7eaa2c70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def maybe_setup_db():\n",
    "    if force_setup_db:\n",
    "        print(\"Forcing DB setup\")\n",
    "        setup_db()\n",
    "    else:\n",
    "        try:\n",
    "            cur = con.cursor()\n",
    "            cur.execute(\"SELECT count(*) FROM patient\")\n",
    "            print(f\"Table exists ({cur.fetchone()[0]}), no need to recreate DB\")\n",
    "        except Exception as ex:\n",
    "            # print(f\"Caught: {ex}\")\n",
    "            cur.close()\n",
    "            if \"no such table: patient\" in str(ex):\n",
    "                print(f\"Table not there, need to recreate DB\")\n",
    "                setup_db()\n",
    "            else:\n",
    "                raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8638e1a5-cce4-4f75-9947-965787a45c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "maybe_setup_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfc11a5-26cf-43da-9a9b-bb858069a845",
   "metadata": {},
   "source": [
    "### In order to make the chatbot conversational, we need to de-contextualize questions\n",
    "\n",
    "For example, if the first question is \"How many patients are over 30?\" and the second question is \"And how many of those have a BMI > 30?\" then we need to rewrite the second question to replace \"those\" with an appropriate referent. For example, we could rewrite the question as \"How many patients that are over 30 also have a BMI > 30?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7c8ff-2e06-49b0-85b0-3d9644b6aa92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decontextualize_question(question: str, messages: List[List[str]]) -> str:\n",
    "    \"\"\"\n",
    "    Each message is a list of [question, answer].\n",
    "    \"\"\"\n",
    "    print(f\"decontextualize_question {question} {messages}\")\n",
    "    prompt_template = \"\"\"\n",
    "I am going to give you a history of questions and answers, followed by a new question.\n",
    "I want you to rewrite to the new question so that it stands alone, not needing the\n",
    "historical context to make sense.\n",
    "\n",
    "<history>\n",
    "{% for x in history %}\n",
    "  <question>{{ x[0] }}</question>\n",
    "  <answer>{{ x[1] }}</answer>\n",
    "{% endfor %}\n",
    "</history>\n",
    "\n",
    "Here is the new question:\n",
    "<new_question>\n",
    "{{question}}\n",
    "</new_question>\n",
    "\n",
    "You must make the absolute MINIMUM changes required to make the meaning of\n",
    "the sentence clear without the context of the history. Make NO other changes.\n",
    "\n",
    "Return the rewritten, standalone, question in <result></result> tags.\n",
    "\"\"\"\n",
    "    prompt = jenv.from_string(prompt_template).render(history=messages, question=question)\n",
    "    # print(f\"prompt:\\n{prompt}\\n-----\")\n",
    "    response = llm.invoke(prompt)\n",
    "    # print(f\"response:\\n{response}\\n--------\")\n",
    "    answer = u.extract_tag(response.content, \"result\")[0]\n",
    "    # print(f\"answer: <<{answer}>>\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c491e-1002-4eb3-8994-e96c186a82de",
   "metadata": {},
   "source": [
    "Extract the `CREATE TABLE` statement from the database and store it away so we can later insert it into the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1802de28-418f-450b-9788-23dd89ab992a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT * FROM sqlite_master\")\n",
    "DDL = cur.fetchone()[4]\n",
    "print(DDL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c251f06-4540-4f09-b453-8215733cfcc3",
   "metadata": {},
   "source": [
    "We use an instance of `BaseCallbackHandler` to introspect on the sequence of LLM calls (tool invocations) so\n",
    "we can later report on useful information about this tool chain like the SQL generated and the number of tool invocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7354d-917d-4673-9c55-61c21572fe9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SQLHandler(BaseCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self._sql_result = []\n",
    "        self._num_tool_actions = 0\n",
    "\n",
    "    def on_agent_action(self, action, **kwargs):\n",
    "        \"\"\"Runs on agent action. if the tool being used is sql_db_query,\n",
    "         it means we're submitting the sql and we can \n",
    "         record it as the final sql\n",
    "        \"\"\"\n",
    "        self._num_tool_actions += 1\n",
    "        if action.tool in [\"sql_db_query_checker\", \"sql_db_query\"]:\n",
    "            self._sql_result.append(action.tool_input)\n",
    "\n",
    "    def sql_results(self) -> List[str]:\n",
    "        return self._sql_result\n",
    "\n",
    "    def num_tool_actions(self) -> int:\n",
    "        return self._num_tool_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53376a82-4bfb-40aa-a4b8-b7c3c08c0795",
   "metadata": {},
   "source": [
    "We can optionally provide notes or hints about the schema to help guide to model towards generating more accurate\n",
    "SQL. In this case the schema is straightforward so we haven't need to add any notes, but you can experiment with adding \n",
    "some in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce4db1-3c19-4d78-871a-dcac27e302c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notes: List[str] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751163c-54e6-436c-8012-0dd3bc252f57",
   "metadata": {},
   "source": [
    "The following is the main prompt that we use to direct the [ReAct](https://arxiv.org/pdf/2210.03629) workflow. Typically this agentic workflow would use the tools sql_db_schema and sql_db_list_tables to extract metadata (the schema) from the database. This requires extra LLM inferences that increases the latency of the overall agentic workflow. Here we both explicitly provide the table name and `CREATE TABLE` statement and also tell the LLM to not call these tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b8f44-9f92-447a-bb4d-27e3b337f1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "Answer the following questions as best you can.\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "You might find the following tips useful:\n",
    "{% for tip in tips %}\n",
    "  - {{ tip }}\n",
    "{% endfor %}\n",
    "\n",
    "The database has the following single table:\n",
    "\n",
    "{{ table_info }}\n",
    "\n",
    "You should NEVER have to use either the sql_db_schema tool or the sql_db_list_tables tool\n",
    "as you know the only table is the \"patients\" table and you know its schema.\n",
    "\n",
    "You NEVER can product SELECT statement with no LIMIT clause. You should always have an ORDER BY\n",
    "clause and a \"LIMIT 20\" to avoid returning too many useless results.\n",
    "\n",
    "When describing the final result you don't have to describe HOW the SQL statement worked,\n",
    "just describe the results.\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84a534-7f6b-4fd4-9237-02144728da1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prompt(notes, DDL, question: str):\n",
    "    prompt_0 = jenv.from_string(prompt_template).render(tips=notes,\n",
    "                                                        table_info=DDL)\n",
    "    prompt = PromptTemplate.from_template(prompt_0)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6edfa-5020-4f9d-a827-08cf89a1a22f",
   "metadata": {},
   "source": [
    "## Answering questions\n",
    "\n",
    "Below we provide two functions, `answer_standalone_question` and `answer_multiple_questions`, that you can use to drive a chatbot. While the interaction here is admitedly crude, you can easily take these functions and plug them into a framework such as [gradio's ChatBot](https://www.gradio.app/docs/gradio/chatbot) to create a more sophisticated UX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00b89e-247f-4920-904b-1ef2a912e475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def answer_standalone_question(question: str,\n",
    "                               messages: List[List[str]]) -> str:\n",
    "    start_time: float = time()\n",
    "    if is_conversational and messages:\n",
    "        question = decontextualize_question(question, messages)\n",
    "    handler = SQLHandler()\n",
    "    try:\n",
    "        agent_executor = create_sql_agent(\n",
    "            llm=llm,\n",
    "            toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n",
    "            verbose=True,\n",
    "            prompt=create_prompt(notes, DDL, question),\n",
    "            agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            callbacks=[handler],\n",
    "            handle_parsing_errors=True)\n",
    "        for iteration in itertools.count(0):\n",
    "            try:\n",
    "                answer = agent_executor.invoke(input={\"input\": question},\n",
    "                                               config={\"callbacks\": [handler]})\n",
    "                duration = time() - start_time\n",
    "                iter_str = f\", {iteration} iterations\" if iteration > 1 else \"\"\n",
    "                history_str = f\", history {len(messages):,}\" if len(messages) > 0 else \"\"\n",
    "                sql_result = handler.sql_results()[-1].strip() if len(handler.sql_results()) > 0\\\n",
    "                             else None\n",
    "                print(f\"sql_result: {sql_result}\")\n",
    "                SQL_str = f\"\\n ```{sql_result}```\" if show_SQL and sql_result else \"\"\n",
    "                return answer['output'],\\\n",
    "                       f\"{duration:.1f} secs, {handler.num_tool_actions():,} actions{iter_str}{history_str} {SQL_str}\"\n",
    "            except ValueError as ex:\n",
    "                if iteration < 10:\n",
    "                    print(f\"iteration #{iteration}: caught {ex}\")\n",
    "                    print(\"retrying\")\n",
    "                else:\n",
    "                    raise ex\n",
    "    except Exception as ex:\n",
    "        print(f\"Caught: {ex}\")\n",
    "        raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71014cc5-480f-440b-9045-ab562aeaec15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def answer_multiple_questions(questions: List[str]) -> List[Tuple[str, str]]:\n",
    "    messages: List[Tuple[str, str]] = []\n",
    "    answers: List[str] = []\n",
    "    for question in questions:\n",
    "        answer, extra_info = answer_standalone_question(question, messages)\n",
    "        answers.append(answer)\n",
    "        messages.append([question, answer])\n",
    "    return list(zip(questions, answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022ff83b",
   "metadata": {},
   "source": [
    "If when executing the next cell you see this error:\n",
    "\n",
    "![model access error](content/model-access-error.png)\n",
    "\n",
    "then you need to go to the Bedrock web console and request model access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bce403-9166-4104-affa-82fca1ea3202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_standalone_question(\"How many patients have a BMI over 20 and are older than 30?\",\n",
    "                           [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ad365-853e-4636-9584-4e6592f7eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_multiple_questions(\n",
    "    [\"How many patients have a BMI over 20 and are older than 30?\",\n",
    "     \"How many are over 50?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a93743-d92d-4992-b647-6a1b3e640532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
